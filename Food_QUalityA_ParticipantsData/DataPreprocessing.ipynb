{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ryan/stark/MachineHack/Food_QUalityA_ParticipantsData'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file into a variable fifa_data\n",
    "filepath = \"/home/ryan/stark/MachineHack/Food_QUalityA_ParticipantsData/Data_Train.xlsx\"\n",
    "data = pd.read_excel(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LicenseNo</th>\n",
       "      <th>FacilityID</th>\n",
       "      <th>FacilityName</th>\n",
       "      <th>Type</th>\n",
       "      <th>Street</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Reason</th>\n",
       "      <th>SectionViolations</th>\n",
       "      <th>RiskLevel</th>\n",
       "      <th>Geo_Loc</th>\n",
       "      <th>Inspection_Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4744</td>\n",
       "      <td>8123</td>\n",
       "      <td>7715</td>\n",
       "      <td>RESTAURANT</td>\n",
       "      <td>15522</td>\n",
       "      <td>id-11235901</td>\n",
       "      <td>id_1890134</td>\n",
       "      <td>81876.0</td>\n",
       "      <td>CANVASS</td>\n",
       "      <td>33.0</td>\n",
       "      <td>High</td>\n",
       "      <td>locid16406</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2973</td>\n",
       "      <td>12268</td>\n",
       "      <td>11664</td>\n",
       "      <td>GROCERY STORE</td>\n",
       "      <td>3057</td>\n",
       "      <td>id-11235901</td>\n",
       "      <td>id_1890134</td>\n",
       "      <td>81862.0</td>\n",
       "      <td>COMPLAINT</td>\n",
       "      <td>33.0</td>\n",
       "      <td>High</td>\n",
       "      <td>locid878</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18223</td>\n",
       "      <td>1112</td>\n",
       "      <td>969</td>\n",
       "      <td>RESTAURANT</td>\n",
       "      <td>14988</td>\n",
       "      <td>id-11235901</td>\n",
       "      <td>id_1890134</td>\n",
       "      <td>81883.0</td>\n",
       "      <td>CANVASS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>locid3368</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LicenseNo  FacilityID  FacilityName           Type  Street         City  \\\n",
       "0       4744        8123          7715     RESTAURANT   15522  id-11235901   \n",
       "1       2973       12268         11664  GROCERY STORE    3057  id-11235901   \n",
       "2      18223        1112           969     RESTAURANT   14988  id-11235901   \n",
       "\n",
       "        State  LocationID     Reason  SectionViolations RiskLevel     Geo_Loc  \\\n",
       "0  id_1890134     81876.0    CANVASS               33.0      High  locid16406   \n",
       "1  id_1890134     81862.0  COMPLAINT               33.0      High    locid878   \n",
       "2  id_1890134     81883.0    CANVASS                NaN      High   locid3368   \n",
       "\n",
       "   Inspection_Results  \n",
       "0                   4  \n",
       "1                   4  \n",
       "2                   6  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata = pd.read_excel('/home/ryan/stark/MachineHack/Food_QUalityA_ParticipantsData/Data_Test.xlsx')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    'Date',\n",
    "    'ID'\n",
    "    ]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147033"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Type'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cata = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cata['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(cols_to_drop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['Date'] = pd.to_datetime(data['Date'] ,errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"Date\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147443, 13)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.002788489658784"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "147443/147033"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SectionViolations</th>\n",
       "      <td>39068</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>3485</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LocationID</th>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inspection_Results</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geo_Loc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RiskLevel</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reason</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Street</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FacilityName</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FacilityID</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LicenseNo</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Total     %\n",
       "SectionViolations   39068  26.5\n",
       "Type                 3485   2.4\n",
       "LocationID             35   0.0\n",
       "Inspection_Results      0   0.0\n",
       "Geo_Loc                 0   0.0\n",
       "RiskLevel               0   0.0\n",
       "Reason                  0   0.0\n",
       "State                   0   0.0\n",
       "City                    0   0.0\n",
       "Street                  0   0.0\n",
       "FacilityName            0   0.0\n",
       "FacilityID              0   0.0\n",
       "LicenseNo               0   0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = data.isnull().sum().sort_values(ascending=False)\n",
    "percent_1 = data.isnull().sum()/data.isnull().count()*100\n",
    "percent_2 = (np.round(percent_1, 1)).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%']) #ptr\n",
    "missing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = data.Inspection_Results\n",
    "\n",
    "# To keep things simple, we'll use only numerical predictors\n",
    "melb_predictors = data.drop(['Inspection_Results'], axis=1)\n",
    "X = melb_predictors.copy() #select_dtypes(exclude=['object']) #since mostly problem is in section violation\n",
    "\n",
    "# Divide data into training and validation subsets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.999, test_size=0.001,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# score_dataset fun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####handler function\n",
    "#######scoring the dataset#########\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestClassifier(random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    #preds = model.predict(X_valid)\n",
    "    #log_loss(y_valid, preds ,labels=[0,1,2,3,4,5,6])\n",
    "    return model.score(X_valid,y_valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_with_missing = [col for col in X_train.columns\n",
    "#                      if X_train[col].isnull().any()]\n",
    "\n",
    "# # Drop columns in training and validation data\n",
    "# reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "# reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n",
    "\n",
    "# print(\"Approach 1 (Drop columns with missing values):\")\n",
    "# print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# # Imputation\n",
    "# my_imputer = SimpleImputer(strategy='constant')\n",
    "# imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "# imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# # Imputation removed column names; put them back\n",
    "# imputed_X_train.columns = X_train.columns\n",
    "# imputed_X_valid.columns = X_valid.columns\n",
    "\n",
    "# print(\"loss from Approach 2 (Imputation):\")\n",
    "# print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# # Imputation\n",
    "# my_imputer = SimpleImputer()\n",
    "# imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "# imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# # Imputation removed column names; put them back\n",
    "# imputed_X_train.columns = X_train.columns\n",
    "# imputed_X_valid.columns = X_valid.columns\n",
    "\n",
    "# print(\"loss from Approach 2 (Imputation):\")\n",
    "# print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# # Imputation\n",
    "# my_imputer = SimpleImputer(strategy='most_frequent')\n",
    "# imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "# imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# # Imputation removed column names; put them back\n",
    "# imputed_X_train.columns = X_train.columns\n",
    "# imputed_X_valid.columns = X_valid.columns\n",
    "\n",
    "# print(\"loss from Approach 2 (Imputation):\")\n",
    "# print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_plus = X_train.copy()\n",
    "# X_valid_plus = X_valid.copy()\n",
    "\n",
    "# # Make new columns indicating what will be imputed\n",
    "# for col in cols_with_missing:\n",
    "#     X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
    "#     X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n",
    "\n",
    "# # Imputation\n",
    "# my_imputer = SimpleImputer()\n",
    "# imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n",
    "# imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n",
    "\n",
    "# # Imputation removed column names; put them back\n",
    "# imputed_X_train_plus.columns = X_train_plus.columns\n",
    "# imputed_X_valid_plus.columns = X_valid_plus.columns\n",
    "\n",
    "# print(\"score from Approach 3 (An Extension to Imputation):\")\n",
    "# print(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########It means second approach is best########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [cname for cname in X.columns if X[cname].nunique() < 500000000000000000 and \n",
    "                        X[cname].dtype == \"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Type', 'City', 'State', 'Reason', 'RiskLevel', 'Geo_Loc']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LicenseNo',\n",
       " 'FacilityID',\n",
       " 'FacilityName',\n",
       " 'Street',\n",
       " 'LocationID',\n",
       " 'SectionViolations']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "datecol = ['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Type',\n",
       " 'City',\n",
       " 'State',\n",
       " 'Reason',\n",
       " 'RiskLevel',\n",
       " 'Geo_Loc',\n",
       " 'LicenseNo',\n",
       " 'FacilityID',\n",
       " 'FacilityName',\n",
       " 'Street',\n",
       " 'LocationID',\n",
       " 'SectionViolations']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cols = categorical_cols + numerical_cols\n",
    "my_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select numerical columns\n",
    "\n",
    "# # Keep selected columns only\n",
    "# my_cols = low_cardinality_cols + numerical_cols\n",
    "# X_train = X[my_cols].copy()\n",
    "# X_valid = X[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "####imputing numerical columns###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nX_train, nX_valid, ny_train, ny_valid = train_test_split(X[numerical_cols], y, train_size=0.8, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# # Imputation\n",
    "# my_imputer = SimpleImputer(strategy='most_frequent')\n",
    "# imNX_train = pd.DataFrame(my_imputer.fit_transform(nX_train))\n",
    "# imNX_valid = pd.DataFrame(my_imputer.transform(nX_valid))\n",
    "\n",
    "# # Imputation removed column names; put them back\n",
    "# imNX_train.columns = nX_train.columns\n",
    "# imNX_valid.columns = nX_valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################imputing catgorical columns######333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cX_train, cX_valid, cy_train, cy_valid = train_test_split(X[low_cardinality_cols], y, train_size=0.8, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_imputer = SimpleImputer(strategy='most_frequent')\n",
    "# imcX_train = pd.DataFrame(my_imputer.fit_transform(cX_train))\n",
    "# imcX_valid = pd.DataFrame(my_imputer.transform(cX_valid))\n",
    "\n",
    "# # Imputation removed column names; put them back\n",
    "# imcX_train.columns = cX_train.columns\n",
    "# imcX_valid.columns = cX_valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pd.concat([imNX_train,imcX_train] ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LicenseNo</th>\n",
       "      <th>FacilityID</th>\n",
       "      <th>FacilityName</th>\n",
       "      <th>Type</th>\n",
       "      <th>Street</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Reason</th>\n",
       "      <th>SectionViolations</th>\n",
       "      <th>RiskLevel</th>\n",
       "      <th>Geo_Loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67528</th>\n",
       "      <td>26121</td>\n",
       "      <td>7628</td>\n",
       "      <td>7252</td>\n",
       "      <td>RESTAURANT</td>\n",
       "      <td>8568</td>\n",
       "      <td>id-11235901</td>\n",
       "      <td>id_1890134</td>\n",
       "      <td>81846.0</td>\n",
       "      <td>LICENSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>locid7682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74634</th>\n",
       "      <td>36379</td>\n",
       "      <td>9294</td>\n",
       "      <td>8818</td>\n",
       "      <td>RESTAURANT</td>\n",
       "      <td>16553</td>\n",
       "      <td>id-11235901</td>\n",
       "      <td>id_1890134</td>\n",
       "      <td>81865.0</td>\n",
       "      <td>CANVASS</td>\n",
       "      <td>33.0</td>\n",
       "      <td>High</td>\n",
       "      <td>locid1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42662</th>\n",
       "      <td>20219</td>\n",
       "      <td>4642</td>\n",
       "      <td>4429</td>\n",
       "      <td>SCHOOL</td>\n",
       "      <td>7225</td>\n",
       "      <td>id-11235901</td>\n",
       "      <td>id_1890134</td>\n",
       "      <td>81897.0</td>\n",
       "      <td>CANVASS</td>\n",
       "      <td>21.0</td>\n",
       "      <td>High</td>\n",
       "      <td>locid1352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LicenseNo  FacilityID  FacilityName        Type  Street         City  \\\n",
       "67528      26121        7628          7252  RESTAURANT    8568  id-11235901   \n",
       "74634      36379        9294          8818  RESTAURANT   16553  id-11235901   \n",
       "42662      20219        4642          4429      SCHOOL    7225  id-11235901   \n",
       "\n",
       "            State  LocationID   Reason  SectionViolations RiskLevel    Geo_Loc  \n",
       "67528  id_1890134     81846.0  LICENSE                NaN      High  locid7682  \n",
       "74634  id_1890134     81865.0  CANVASS               33.0      High  locid1912  \n",
       "42662  id_1890134     81897.0  CANVASS               21.0      High  locid1352  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_valid = pd.concat([imNX_valid,imcX_valid] ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LicenseNo</th>\n",
       "      <th>FacilityID</th>\n",
       "      <th>FacilityName</th>\n",
       "      <th>Type</th>\n",
       "      <th>Street</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Reason</th>\n",
       "      <th>SectionViolations</th>\n",
       "      <th>RiskLevel</th>\n",
       "      <th>Geo_Loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76851</th>\n",
       "      <td>28225</td>\n",
       "      <td>4702</td>\n",
       "      <td>4480</td>\n",
       "      <td>RESTAURANT</td>\n",
       "      <td>13072</td>\n",
       "      <td>id-11235901</td>\n",
       "      <td>id_1890134</td>\n",
       "      <td>81875.0</td>\n",
       "      <td>CANVASS</td>\n",
       "      <td>2.0</td>\n",
       "      <td>High</td>\n",
       "      <td>locid15302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36203</th>\n",
       "      <td>743</td>\n",
       "      <td>25793</td>\n",
       "      <td>24635</td>\n",
       "      <td>CAFE/STORE</td>\n",
       "      <td>2087</td>\n",
       "      <td>id-11235901</td>\n",
       "      <td>id_1890134</td>\n",
       "      <td>81882.0</td>\n",
       "      <td>CANVASS</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>locid3211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>24297</td>\n",
       "      <td>13257</td>\n",
       "      <td>12588</td>\n",
       "      <td>RESTAURANT</td>\n",
       "      <td>2382</td>\n",
       "      <td>id-11235901</td>\n",
       "      <td>id_1890134</td>\n",
       "      <td>81855.0</td>\n",
       "      <td>CANVASS RE-INSPECTION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>locid9774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51377</th>\n",
       "      <td>18030</td>\n",
       "      <td>7609</td>\n",
       "      <td>7234</td>\n",
       "      <td>SCHOOL</td>\n",
       "      <td>12441</td>\n",
       "      <td>id-11235901</td>\n",
       "      <td>id_1890134</td>\n",
       "      <td>81883.0</td>\n",
       "      <td>CANVASS</td>\n",
       "      <td>32.0</td>\n",
       "      <td>High</td>\n",
       "      <td>locid3875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116892</th>\n",
       "      <td>17544</td>\n",
       "      <td>23678</td>\n",
       "      <td>22588</td>\n",
       "      <td>RESTAURANT</td>\n",
       "      <td>479</td>\n",
       "      <td>id-11235901</td>\n",
       "      <td>id_1890134</td>\n",
       "      <td>81862.0</td>\n",
       "      <td>CANVASS</td>\n",
       "      <td>33.0</td>\n",
       "      <td>High</td>\n",
       "      <td>locid511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LicenseNo  FacilityID  FacilityName        Type  Street         City  \\\n",
       "76851       28225        4702          4480  RESTAURANT   13072  id-11235901   \n",
       "36203         743       25793         24635  CAFE/STORE    2087  id-11235901   \n",
       "3760        24297       13257         12588  RESTAURANT    2382  id-11235901   \n",
       "51377       18030        7609          7234      SCHOOL   12441  id-11235901   \n",
       "116892      17544       23678         22588  RESTAURANT     479  id-11235901   \n",
       "\n",
       "             State  LocationID                 Reason  SectionViolations  \\\n",
       "76851   id_1890134     81875.0                CANVASS                2.0   \n",
       "36203   id_1890134     81882.0                CANVASS               32.0   \n",
       "3760    id_1890134     81855.0  CANVASS RE-INSPECTION                NaN   \n",
       "51377   id_1890134     81883.0                CANVASS               32.0   \n",
       "116892  id_1890134     81862.0                CANVASS               33.0   \n",
       "\n",
       "       RiskLevel     Geo_Loc  \n",
       "76851       High  locid15302  \n",
       "36203     Medium   locid3211  \n",
       "3760        High   locid9774  \n",
       "51377       High   locid3875  \n",
       "116892      High    locid511  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "### perdorm suitable imputation selected from above\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputation\n",
    "my_imputer = SimpleImputer(strategy='most_frequent')\n",
    "imX_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imX_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imX_train.columns = X_train.columns\n",
    "imX_valid.columns = X_valid.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "####convert back to datatypes \n",
    "imX_train[numerical_cols] = imX_train[numerical_cols].apply(pd.to_numeric, errors='coerce')\n",
    "imX_valid[numerical_cols] = imX_valid[numerical_cols].apply(pd.to_numeric, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'SCHOOL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-4fdde8ab48a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-f34207e35873>\u001b[0m in \u001b[0;36mscore_dataset\u001b[0;34m(X_train, X_valid, y_train, y_valid)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscore_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m#preds = model.predict(X_valid)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#log_loss(y_valid, preds ,labels=[0,1,2,3,4,5,6])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \"\"\"\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'SCHOOL'"
     ]
    }
   ],
   "source": [
    "print(score_dataset(imX_train, imX_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LicenseNo              int64\n",
       "FacilityID             int64\n",
       "FacilityName           int64\n",
       "Type                  object\n",
       "Street                 int64\n",
       "City                  object\n",
       "State                 object\n",
       "LocationID           float64\n",
       "Reason                object\n",
       "SectionViolations    float64\n",
       "RiskLevel             object\n",
       "Geo_Loc               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imX_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LicenseNo              int64\n",
       "FacilityID             int64\n",
       "FacilityName           int64\n",
       "Type                  object\n",
       "Street                 int64\n",
       "City                  object\n",
       "State                 object\n",
       "LocationID           float64\n",
       "Reason                object\n",
       "SectionViolations    float64\n",
       "RiskLevel             object\n",
       "Geo_Loc               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imX_valid.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables:\n",
      "['Type', 'City', 'State', 'Reason', 'RiskLevel', 'Geo_Loc']\n"
     ]
    }
   ],
   "source": [
    "# Get list of categorical variables\n",
    "s = (imX_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(\"Categorical variables:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([123026]),)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.where(np.array(X['Geo_Loc']) ==['locid9665'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X['Geo_Loc'][123026] = 'locid7682'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'locid7682'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Geo_Loc'][123026]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'locid9665'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'locid9665'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-1e0a0ff35524>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobject_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlabel_X_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlabel_X_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimX_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" loss from Approach 1 (Label Encoding):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"argument must be a string or number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             raise ValueError(\"y contains previously unseen labels: %s\"\n\u001b[0;32m---> 68\u001b[0;31m                              % str(e))\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: 'locid9665'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Make copy to avoid changing original data \n",
    "label_X_train = imX_train.copy()\n",
    "label_X_valid = imX_valid.copy()\n",
    "\n",
    "# Apply label encoder to each column with categorical data\n",
    "label_encoder = LabelEncoder()\n",
    "for col in object_cols:\n",
    "    label_X_train[col] = label_encoder.fit_transform(imX_train[col])\n",
    "    label_X_valid[col] = label_encoder.transform(imX_valid[col])\n",
    "\n",
    "print(\" loss from Approach 1 (Label Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (147443, 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-726c58723cc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabel_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobject_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlabel_X_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#label_X_valid[col] = label_encoder.transform(imX_valid[col])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \"\"\"\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (147443, 12)"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "for col in object_cols:\n",
    "    label_X_train[col] = label_encoder.fit_transform(X)\n",
    "    #label_X_valid[col] = label_encoder.transform(imX_valid[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                           RESTAURANT\n",
      "1                        GROCERY STORE\n",
      "2                           RESTAURANT\n",
      "3                           RESTAURANT\n",
      "4                           RESTAURANT\n",
      "                      ...             \n",
      "147438                   GROCERY STORE\n",
      "147439                      RESTAURANT\n",
      "147440                      RESTAURANT\n",
      "147441                      RESTAURANT\n",
      "147442    CHILDREN'S SERVICES FACILITY\n",
      "Name: Type, Length: 147443, dtype: object\n",
      "0         id-11235901\n",
      "1         id-11235901\n",
      "2         id-11235901\n",
      "3         id-11235901\n",
      "4         id-11235901\n",
      "             ...     \n",
      "147438    id-11235901\n",
      "147439    id-11235901\n",
      "147440    id-11235901\n",
      "147441    id-11235901\n",
      "147442    id-11235901\n",
      "Name: City, Length: 147443, dtype: object\n",
      "0         id_1890134\n",
      "1         id_1890134\n",
      "2         id_1890134\n",
      "3         id_1890134\n",
      "4         id_1890134\n",
      "             ...    \n",
      "147438    id_1890134\n",
      "147439    id_1890134\n",
      "147440    id_1890134\n",
      "147441    id_1890134\n",
      "147442    id_1890134\n",
      "Name: State, Length: 147443, dtype: object\n",
      "0                       CANVASS\n",
      "1                     COMPLAINT\n",
      "2                       CANVASS\n",
      "3         CANVASS RE-INSPECTION\n",
      "4                     COMPLAINT\n",
      "                  ...          \n",
      "147438                COMPLAINT\n",
      "147439     SHORT FORM COMPLAINT\n",
      "147440                  CANVASS\n",
      "147441    CANVASS RE-INSPECTION\n",
      "147442                  LICENSE\n",
      "Name: Reason, Length: 147443, dtype: object\n",
      "0           High\n",
      "1           High\n",
      "2           High\n",
      "3         Medium\n",
      "4           High\n",
      "           ...  \n",
      "147438    Medium\n",
      "147439      High\n",
      "147440    Medium\n",
      "147441      High\n",
      "147442      High\n",
      "Name: RiskLevel, Length: 147443, dtype: object\n",
      "0         locid16406\n",
      "1           locid878\n",
      "2          locid3368\n",
      "3         locid11839\n",
      "4         locid12264\n",
      "             ...    \n",
      "147438      locid203\n",
      "147439     locid7202\n",
      "147440     locid3614\n",
      "147441      locid757\n",
      "147442    locid16090\n",
      "Name: Geo_Loc, Length: 147443, dtype: object\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "for col in object_cols:\n",
    "    print(X[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
