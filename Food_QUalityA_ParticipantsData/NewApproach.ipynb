{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kFEo8EwDLq1H",
    "outputId": "3a82fbf3-bed9-41fb-f462-205cb544e604"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import category_encoders\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import matplotlib as plt\n",
    "from random import randint\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qoz1hAGBLq1Q"
   },
   "outputs": [],
   "source": [
    "# Read the file into a variable fifa_data\n",
    "filepath = \"/home/ryan/stark/MachineHack/Food_QUalityA_ParticipantsData/Data_Train.xlsx\"\n",
    "train = pd.read_excel(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file into a variable fifa_data\n",
    " \n",
    "test = pd.read_excel(\"/home/ryan/stark/MachineHack/Food_QUalityA_ParticipantsData/Data_Test.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hbEjJjM0Lq1X"
   },
   "outputs": [],
   "source": [
    "submission= pd.read_excel('/home/ryan/stark/MachineHack/Food_QUalityA_ParticipantsData/Sample_Submission.xlsx')\n",
    "# data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQx71DcSLq1v"
   },
   "outputs": [],
   "source": [
    "class LabelEncoderExt(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
    "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
    "        \"\"\"\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        # self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "    def fit(self, data_list):\n",
    "        \"\"\"\n",
    "        This will fit the encoder for all the unique values and introduce unknown value\n",
    "        :param data_list: A list of string\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
    "        self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_list):\n",
    "        \"\"\"\n",
    "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
    "        :param data_list:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        new_data_list = list(data_list)\n",
    "        for unique_item in np.unique(data_list):\n",
    "            if unique_item not in self.label_encoder.classes_:\n",
    "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
    "\n",
    "        return self.label_encoder.transform(new_data_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# clf1 = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
    "#                        max_depth=None, max_features=11, max_leaf_nodes=None,\n",
    "#                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#                        min_samples_leaf=8, min_samples_split=2,\n",
    "#                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "#                        random_state=None, splitter='best')\n",
    "\n",
    "# clf2 = BaggingClassifier(base_estimator=clf1, n_estimators=100, max_samples=1.0, max_features=1.0, \n",
    "#                          bootstrap=True,\n",
    "#                          bootstrap_features=False, oob_score=True, warm_start=False,\n",
    "#                          n_jobs=-1, random_state=None, verbose=0)\n",
    "\n",
    "# clf3=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "#               colsample_bynode=1, colsample_bytree=0.8, gamma=0.5,\n",
    "#               learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
    "#               min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
    "#               nthread=None, objective='multi:softprob', random_state=0,\n",
    "#               reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "#               silent=None, subsample=0.6, verbosity=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xaOKY4bpLq11"
   },
   "outputs": [],
   "source": [
    "def dropcol(train,test):\n",
    "    train['logID'] = np.log1p(train['ID'])\n",
    "    test['logID'] = np.log1p(test['ID'])\n",
    "    cols_to_drop = ['Date','ID']\n",
    "    dtrain = train.drop(cols_to_drop,axis =1)\n",
    "    dtest = test.drop(cols_to_drop,axis =1)\n",
    "    \n",
    "    print(dtrain.shape,dtest.shape)\n",
    "\n",
    "    return dtrain,dtest\n",
    "\n",
    "def catVar1(data):\n",
    "    categorical_colsT1 = [cname for cname in data.columns if\n",
    "                    data[cname].nunique() <=10 and \n",
    "                    data[cname].dtype == \"object\"]\n",
    "    return categorical_colsT1\n",
    "\n",
    "def catVar2(data):\n",
    "    categorical_colsT2 = [cname for cname in data.columns if\n",
    "                    data[cname].nunique() >10 and \n",
    "                    data[cname].dtype == \"object\"]\n",
    "    return categorical_colsT2\n",
    "\n",
    "def NumVar(data) :\n",
    "    numerical_cols = [cname for cname in data.columns if \n",
    "    data[cname].dtype in ['int64', 'float64']]\n",
    "    return numerical_cols\n",
    "\n",
    "def imputer(train,test):\n",
    "    \n",
    "    from sklearn.impute import SimpleImputer\n",
    "    \n",
    "    numerical_cols = NumVar(train)\n",
    "    my_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    imputed_train = pd.DataFrame(my_imputer.fit_transform(train))\n",
    "    imputed_test = pd.DataFrame(my_imputer.transform(test))\n",
    "\n",
    "    # Imputation removed column names; put them back\n",
    "    imputed_train.columns = train.columns\n",
    "    imputed_test.columns = test.columns\n",
    "    \n",
    "    #restoring datatypes \n",
    "    imputed_train[numerical_cols] = imputed_train[numerical_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    imputed_test[numerical_cols] = imputed_test[numerical_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    print(imputed_train.shape,imputed_test.shape)\n",
    "    return imputed_train,imputed_test \n",
    "\n",
    "def robustlabelencoder(train,test):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    label_enc = LabelEncoderExt()\n",
    "    cols = catVar2(train)\n",
    "    print(cols)\n",
    "    for col in cols:\n",
    "        label_enc.fit(train[col])\n",
    "        train[col] = label_enc.transform(train[col])\n",
    "        test[col] = label_enc.transform(test[col])\n",
    "        \n",
    "    print(train.shape,test.shape)\n",
    "    \n",
    "    return train,test\n",
    "\n",
    "def normalabelencoder(train,test,cols):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    label_enc = LabelEncoder()\n",
    "    \n",
    "    print(cols)\n",
    "    for col in cols:\n",
    "        label_enc.fit(train[col])\n",
    "        train[col] = label_enc.transform(train[col])\n",
    "        test[col] = label_enc.transform(test[col])\n",
    "    \n",
    "    return train,test\n",
    "\n",
    "\n",
    "\n",
    "def ohebygetdummis(train,test):\n",
    "    pass\n",
    "\n",
    "def onhotencoder(train,test):\n",
    "    \n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    object_cols = catVar1(train) #catVar1 gives desired categorical column and not all object columns\n",
    "    print(object_cols)\n",
    "    \n",
    "    OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train[object_cols]))\n",
    "    OH_cols_test = pd.DataFrame(OH_encoder.transform(test[object_cols]))\n",
    "\n",
    "    # One-hot encoding removed index; put it back\n",
    "    OH_cols_train.index = train.index\n",
    "    OH_cols_test.index = test.index\n",
    "\n",
    "    ##hack for restoring columns names just like get dummies\n",
    "    column_name = OH_encoder.get_feature_names(object_cols)\n",
    "    OH_cols_train.columns = column_name\n",
    "    OH_cols_test.columns = column_name\n",
    "    \n",
    "\n",
    "    # Remove desired categorical columns (will replace with one-hot encoding)\n",
    "    num_train = train.drop(object_cols, axis=1)\n",
    "    num_test = test.drop(object_cols, axis=1)\n",
    "\n",
    "    # Add one-hot encoded columns to numerical/remaining features\n",
    "    OH_train = pd.concat([num_train, OH_cols_train], axis=1)\n",
    "    OH_test = pd.concat([num_test, OH_cols_test], axis=1)\n",
    "    \n",
    "    print(OH_train.shape,OH_test.shape)\n",
    "    \n",
    "    \n",
    "    return OH_train,OH_test\n",
    "\n",
    "def missingcheck(data):\n",
    "    total = data.isnull().sum().sort_values(ascending=False)\n",
    "    percent_1 = data.isnull().sum()/data.isnull().count()*100\n",
    "    percent_2 = (np.round(percent_1, 1)).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%']) #ptr\n",
    "    return missing_data\n",
    "\n",
    "def targetencoding(train,test,y_train):\n",
    "    import category_encoders as ce\n",
    "    # Create the encoder itself\n",
    "    cat_features = catVar2(train)\n",
    "    print(f'targest emcoding for features {cat_features}')\n",
    "    target_enc = ce.TargetEncoder(cols=cat_features)\n",
    "\n",
    "    \n",
    "\n",
    "    # Fit the encoder using the categorical features and target\n",
    "    target_enc.fit(train[cat_features], y_train)\n",
    "    \n",
    "\n",
    "    # Transform the features, rename the columns with _target suffix, and join to dataframe\n",
    "    traintrgtenc = train.join(target_enc.transform(train[cat_features]).add_suffix('_target'))\n",
    "    testtrgtenc = test.join(target_enc.transform(test[cat_features]).add_suffix('_target'))\n",
    "\n",
    "    traintrgtenc = traintrgtenc.drop(cat_features, axis =1)\n",
    "    testtrgtenc = testtrgtenc.drop(cat_features, axis =1)\n",
    "\n",
    "    \n",
    "    print(traintrgtenc.shape,testtrgtenc.shape)\n",
    "    \n",
    "    return traintrgtenc,testtrgtenc\n",
    "\n",
    "\n",
    "def special(train,test):\n",
    "    train['Geo_Loc'] = train['Geo_Loc'].str.replace(r'\\D', '')\n",
    "    train['Geo_Loc'] = pd.to_numeric(train['Geo_Loc'], errors='coerce') \n",
    "    \n",
    "    test['Geo_Loc'] = test['Geo_Loc'].str.replace(r'\\D', '')\n",
    "    test['Geo_Loc'] = pd.to_numeric(test['Geo_Loc'], errors='coerce')\n",
    "    \n",
    "    train['Date'] = pd.to_datetime(train['Date'] ,errors='coerce')\n",
    "    test['Date'] = pd.to_datetime(test['Date'] ,errors='coerce')\n",
    "    \n",
    "    train = train.assign(\n",
    "               hour=train.Date.dt.hour,\n",
    "               day=train.Date.dt.day,\n",
    "               month=train.Date.dt.month,\n",
    "               year=train.Date.dt.year\n",
    "                        )\n",
    "    \n",
    "    test = test.assign(\n",
    "               hour=test.Date.dt.hour,\n",
    "               day=test.Date.dt.day,\n",
    "               month=test.Date.dt.month,\n",
    "               year=test.Date.dt.year\n",
    "                        )\n",
    "    print(train.shape,test.shape)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n0gqe6UoLq15"
   },
   "outputs": [],
   "source": [
    "# def syntheticvariable(train , y ):\n",
    "#     from imblearn.over_sampling import SMOTENC\n",
    "#     from collections import Counter\n",
    "#     categorical_features = [cname.index for cname in train.columns if train[cname].dtype == \"object\"]\n",
    "#     out = np.argwhere(train.columns.isin(categorical_features)).ravel().tolist()\n",
    "    \n",
    "#     smote_nc = SMOTENC([3, 5, 6, 8, 10], random_state=0)  #instead of passing out i need to hardcode it.\n",
    "\n",
    "#     X_resampled, y_resampled = smote_nc.fit_resample(train,y)\n",
    "    \n",
    "#     print(sorted(Counter(y_resampled).items()))\n",
    "    \n",
    "#     return X_resampled,y_resampled\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "glt8kTxZLq1-"
   },
   "outputs": [],
   "source": [
    "#####crete new features###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tTTM9ah-Lq2F"
   },
   "outputs": [],
   "source": [
    "def createIntercations(train,test,cat_features):\n",
    "    import itertools\n",
    "    print(f\"Creating features on {cat_features}, with combination 2 for training data /n\")\n",
    "    interactionstrain = pd.DataFrame(index=train.index)\n",
    "    \n",
    "    for col1 ,col2 in  itertools.combinations(cat_features,2):   \n",
    "        newcolname = col1 + \"_\" + col2 \n",
    "        new_values = train[col1].map(str) + \"_\" + train[col2].map(str)\n",
    "        interactionstrain[newcolname] = new_values\n",
    "\n",
    "    \n",
    "    train_df = train.join(interactionstrain)\n",
    "    \n",
    "    print(f\"Creating features on {cat_features}, with combination 2 for testing data\")\n",
    "    interactionstest = pd.DataFrame(index=train.index)\n",
    "    \n",
    "    for col1 ,col2 in  itertools.combinations(cat_features,2):   \n",
    "        newcolname = col1 + \"_\" + col2 \n",
    "        new_values = test[col1].map(str) + \"_\" + test[col2].map(str)\n",
    "        interactionstest[newcolname] = new_values\n",
    "\n",
    "    test_df = test.join(interactionstest)\n",
    "    \n",
    "    print(train_df.shape,test_df.shape)\n",
    "    \n",
    "    \n",
    "    return train_df,test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6CI5m2cLq2K"
   },
   "outputs": [],
   "source": [
    "def createmeanfestures(train,test ,features):\n",
    "  \n",
    "  cols = features\n",
    "  interactionstrain = pd.DataFrame(index=train.index)\n",
    "  interactionstest = pd.DataFrame(index=test.index)\n",
    "\n",
    "  for col  in cols:   \n",
    "        newcolname = col + \"_mean\"   \n",
    "        new_values = train[col].mean()\n",
    "        interactionstrain[newcolname] = new_values\n",
    "\n",
    "  for col  in cols:   \n",
    "        newcolname = col + \"_mean\"   \n",
    "        new_values = test[col].mean()\n",
    "        interactionstest[newcolname] = new_values\n",
    "\n",
    "\n",
    "  train_df = train.join(interactionstrain)\n",
    "  test_df = test.join(interactionstest)\n",
    "\n",
    "  print(train_df.shape,test_df.shape)\n",
    "\n",
    "  return train_df,test_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def createlogfestures(train,test,features):\n",
    "  \n",
    "  cols = features\n",
    "  interactionstrain = pd.DataFrame(index=train.index)\n",
    "  interactionstest = pd.DataFrame(index=test.index)\n",
    "  for col  in cols:   \n",
    "        newcolname = col + \"_log\"   \n",
    "        new_values = np.log1p(train[col])\n",
    "        interactionstrain[newcolname] = new_values\n",
    "\n",
    "  for col  in cols:   \n",
    "        newcolname = col + \"_log\"   \n",
    "        new_values = np.log1p(test[col])\n",
    "        interactionstest[newcolname] = new_values\n",
    "\n",
    "\n",
    "  train_df = train.join(interactionstrain)\n",
    "  test_df = test.join(interactionstest)\n",
    "\n",
    "  print(train_df.shape,test_df.shape)\n",
    "\n",
    "\n",
    "  return train_df ,test_df\n",
    "\n",
    "def createsqrtfeatures(train,test,features):\n",
    "    \n",
    "\n",
    "  cols = features\n",
    "  interactionstrain = pd.DataFrame(index=train.index)\n",
    "  interactionstest = pd.DataFrame(index=test.index)\n",
    "  \n",
    "  for col  in cols:   \n",
    "        newcolname = col + \"_sqrt\"   \n",
    "        new_values = np.sqrt(train[col])\n",
    "        interactionstrain[newcolname] = new_values\n",
    "\n",
    "  for col  in cols:   \n",
    "        newcolname = col + \"_sqrt\"   \n",
    "        new_values = np.sqrt(test[col])\n",
    "        interactionstest[newcolname] = new_values\n",
    "\n",
    "\n",
    "  train_df = train.join(interactionstrain)\n",
    "  test_df = test.join(interactionstest)\n",
    "\n",
    "  print(train_df.shape,test_df.shape)\n",
    "\n",
    "\n",
    "  return train_df ,test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H4qIejjhLq2O"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "    \n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    #model = RandomForestClassifier(random_state=0)\n",
    "    #model.fit(X_train, y_train)\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "    from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "    clf1 = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
    "                       max_depth=None, max_features=21, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=8, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                       random_state=None, splitter='best')\n",
    "\n",
    "    clf2 = BaggingClassifier(base_estimator=clf1, n_estimators=10, \n",
    "                             bootstrap=True,\n",
    "                             bootstrap_features=False, oob_score=True, warm_start=False,\n",
    "                             n_jobs=-1, random_state=786, verbose=0)\n",
    "    clf2.fit(X_train,y_train)\n",
    "\n",
    "    preds = clf2.predict(X_valid)\n",
    "    target_names = ['class 0', 'class 1', 'class 2','class 3', 'class 4', 'class 5', 'class 6']\n",
    "    print(classification_report(y_valid, preds, target_names=target_names,labels= [0,1,2,3,4,5,6]))\n",
    "    return clf2.score(X_valid,y_valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Inspection_Results'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196591, 15)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = train.append(test).reset_index(drop=True)\n",
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missingcheck(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['Geo_Loc'] = full_data['Geo_Loc'].str.replace(r'\\D', '')\n",
    "full_data['Geo_Loc'] = pd.to_numeric(full_data['Geo_Loc'], errors='coerce') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tackling date\n",
    "full_data['Date'] = full_data['Date'].replace('29-02-2011', '28-02-2011')\n",
    "full_data['Date'] = full_data['Date'].replace('29-02-2015', '28-02-2015')\n",
    "full_data['Date'] = pd.to_datetime(full_data['Date'] ,errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating features out of date\n",
    "full_data = full_data.assign(hour=full_data.Date.dt.hour,\n",
    "               day=full_data.Date.dt.day,\n",
    "               month=full_data.Date.dt.month,\n",
    "               year=full_data.Date.dt.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SectionViolations</th>\n",
       "      <td>52044</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>4700</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LocationID</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LicenseNo</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FacilityID</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FacilityName</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Street</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reason</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RiskLevel</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geo_Loc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inspection_Results</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Total     %\n",
       "SectionViolations   52044  26.5\n",
       "Type                 4700   2.4\n",
       "LocationID             50   0.0\n",
       "State                   0   0.0\n",
       "Date                    0   0.0\n",
       "LicenseNo               0   0.0\n",
       "FacilityID              0   0.0\n",
       "FacilityName            0   0.0\n",
       "Street                  0   0.0\n",
       "City                    0   0.0\n",
       "year                    0   0.0\n",
       "month                   0   0.0\n",
       "Reason                  0   0.0\n",
       "RiskLevel               0   0.0\n",
       "Geo_Loc                 0   0.0\n",
       "Inspection_Results      0   0.0\n",
       "hour                    0   0.0\n",
       "day                     0   0.0\n",
       "ID                      0   0.0"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missingcheck(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.SectionViolations = full_data.SectionViolations.fillna(method = 'backfill')\n",
    "full_data.Type = full_data.Type.fillna(method = 'backfill')\n",
    "# full_data.hour = full_data.hour.fillna(method = 'backfill')\n",
    "# full_data.day = full_data.day.fillna(method = 'backfill')\n",
    "# full_data.month = full_data.month.fillna(method = 'backfill')\n",
    "# full_data.year = full_data.year.fillna(method = 'backfill')\n",
    "full_data.LocationID = full_data.LocationID.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LicenseNo</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FacilityID</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FacilityName</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Street</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LocationID</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reason</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SectionViolations</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RiskLevel</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geo_Loc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inspection_Results</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Total    %\n",
       "year                    0  0.0\n",
       "State                   0  0.0\n",
       "Date                    0  0.0\n",
       "LicenseNo               0  0.0\n",
       "FacilityID              0  0.0\n",
       "FacilityName            0  0.0\n",
       "Type                    0  0.0\n",
       "Street                  0  0.0\n",
       "City                    0  0.0\n",
       "LocationID              0  0.0\n",
       "month                   0  0.0\n",
       "Reason                  0  0.0\n",
       "SectionViolations       0  0.0\n",
       "RiskLevel               0  0.0\n",
       "Geo_Loc                 0  0.0\n",
       "Inspection_Results      0  0.0\n",
       "hour                    0  0.0\n",
       "day                     0  0.0\n",
       "ID                      0  0.0"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missingcheck(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data =full_data.drop(['Date','ID'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['SectionViolations','RiskLevel','Reason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196586</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196587</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196588</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196589</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196590</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196591 rows Ã— 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
       "\n",
       "[196591 rows x 0 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "interactions = pd.DataFrame(index=full_data.index)\n",
    "interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 ,col2 in  itertools.combinations(cat_features,2):\n",
    "    \n",
    "    newcolname = col1 + \"_\" + col2 \n",
    "    new_values = full_data[col1].map(str) + \"_\" + full_data[col2].map(str)\n",
    "    interactions[newcolname] = new_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = full_data.join(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions2 = pd.DataFrame(index=full_data.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2 = ['State', 'City', 'Street', 'LocationID', 'Geo_Loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 ,col2 in  itertools.combinations(features2,2):\n",
    "    \n",
    "    newcolname = col1 + \"_\" + col2 \n",
    "    new_values = full_data[col1].map(str) + \"_\" + full_data[col2].map(str)\n",
    "    interactions2[newcolname] = new_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = full_data.join(interactions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196591, 30)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LicenseNo', 'FacilityID', 'FacilityName', 'Type', 'Street', 'City',\n",
       "       'State', 'LocationID', 'Reason', 'SectionViolations', 'RiskLevel',\n",
       "       'Geo_Loc', 'Inspection_Results', 'hour', 'day', 'month', 'year',\n",
       "       'SectionViolations_RiskLevel', 'SectionViolations_Reason',\n",
       "       'RiskLevel_Reason', 'State_City', 'State_Street', 'State_LocationID',\n",
       "       'State_Geo_Loc', 'City_Street', 'City_LocationID', 'City_Geo_Loc',\n",
       "       'Street_LocationID', 'Street_Geo_Loc', 'LocationID_Geo_Loc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = full_data[full_data['Inspection_Results'] != -1]\n",
    "test_data = full_data[full_data['Inspection_Results'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data.Inspection_Results\n",
    "train_data = train_data.drop(['Inspection_Results'], axis=1)\n",
    "test_data = test_data.drop(['Inspection_Results'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, y, train_size=0.80, test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Type', 'Reason', 'SectionViolations_RiskLevel', 'SectionViolations_Reason', 'RiskLevel_Reason', 'State_Street', 'State_LocationID', 'State_Geo_Loc', 'City_Street', 'City_LocationID', 'City_Geo_Loc', 'Street_LocationID', 'Street_Geo_Loc', 'LocationID_Geo_Loc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/ryan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117954, 29) (29489, 29)\n"
     ]
    }
   ],
   "source": [
    "traintrgtenc,testtrgtenc = robustlabelencoder(X_train,X_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['City', 'State', 'RiskLevel', 'State_City']\n",
      "(117954, 37) (29489, 37)\n"
     ]
    }
   ],
   "source": [
    "traintrgtencohe,testtrgtencohe = onhotencoder(traintrgtenc,testtrgtenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LicenseNo</th>\n",
       "      <th>FacilityID</th>\n",
       "      <th>FacilityName</th>\n",
       "      <th>Type</th>\n",
       "      <th>Street</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Reason</th>\n",
       "      <th>SectionViolations</th>\n",
       "      <th>Geo_Loc</th>\n",
       "      <th>hour</th>\n",
       "      <th>...</th>\n",
       "      <th>State_id_1890134</th>\n",
       "      <th>State_id_1890135</th>\n",
       "      <th>RiskLevel_High</th>\n",
       "      <th>RiskLevel_Low</th>\n",
       "      <th>RiskLevel_Medium</th>\n",
       "      <th>RiskLevel_Uncertain</th>\n",
       "      <th>State_City_id_1890134_id-11235901</th>\n",
       "      <th>State_City_id_1890134_id-11275913</th>\n",
       "      <th>State_City_id_1890135_id-11235901</th>\n",
       "      <th>State_City_id_1890135_id-11275913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42067</th>\n",
       "      <td>14062</td>\n",
       "      <td>24159</td>\n",
       "      <td>16384</td>\n",
       "      <td>387</td>\n",
       "      <td>11702</td>\n",
       "      <td>81854.0</td>\n",
       "      <td>7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4242</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93121</th>\n",
       "      <td>30876</td>\n",
       "      <td>26907</td>\n",
       "      <td>25673</td>\n",
       "      <td>314</td>\n",
       "      <td>17128</td>\n",
       "      <td>81856.0</td>\n",
       "      <td>6</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9043</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86355</th>\n",
       "      <td>10360</td>\n",
       "      <td>19353</td>\n",
       "      <td>18492</td>\n",
       "      <td>314</td>\n",
       "      <td>11105</td>\n",
       "      <td>81863.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13961</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14478</th>\n",
       "      <td>27268</td>\n",
       "      <td>3670</td>\n",
       "      <td>3463</td>\n",
       "      <td>314</td>\n",
       "      <td>16421</td>\n",
       "      <td>81859.0</td>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11916</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112515</th>\n",
       "      <td>34144</td>\n",
       "      <td>10068</td>\n",
       "      <td>9555</td>\n",
       "      <td>314</td>\n",
       "      <td>1173</td>\n",
       "      <td>81911.0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16551</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41993</th>\n",
       "      <td>10984</td>\n",
       "      <td>12219</td>\n",
       "      <td>11623</td>\n",
       "      <td>314</td>\n",
       "      <td>3887</td>\n",
       "      <td>81867.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9498</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97639</th>\n",
       "      <td>23404</td>\n",
       "      <td>9401</td>\n",
       "      <td>8915</td>\n",
       "      <td>314</td>\n",
       "      <td>1173</td>\n",
       "      <td>81911.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16551</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95939</th>\n",
       "      <td>17061</td>\n",
       "      <td>7663</td>\n",
       "      <td>7284</td>\n",
       "      <td>314</td>\n",
       "      <td>7518</td>\n",
       "      <td>81870.0</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14718</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117952</th>\n",
       "      <td>4757</td>\n",
       "      <td>6345</td>\n",
       "      <td>6079</td>\n",
       "      <td>314</td>\n",
       "      <td>13253</td>\n",
       "      <td>81886.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12351</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43567</th>\n",
       "      <td>34597</td>\n",
       "      <td>18877</td>\n",
       "      <td>18047</td>\n",
       "      <td>314</td>\n",
       "      <td>17738</td>\n",
       "      <td>81859.0</td>\n",
       "      <td>13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11904</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117954 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        LicenseNo  FacilityID  FacilityName  Type  Street  LocationID  Reason  \\\n",
       "42067       14062       24159         16384   387   11702     81854.0       7   \n",
       "93121       30876       26907         25673   314   17128     81856.0       6   \n",
       "86355       10360       19353         18492   314   11105     81863.0       1   \n",
       "14478       27268        3670          3463   314   16421     81859.0       3   \n",
       "112515      34144       10068          9555   314    1173     81911.0       0   \n",
       "...           ...         ...           ...   ...     ...         ...     ...   \n",
       "41993       10984       12219         11623   314    3887     81867.0       0   \n",
       "97639       23404        9401          8915   314    1173     81911.0       0   \n",
       "95939       17061        7663          7284   314    7518     81870.0       3   \n",
       "117952       4757        6345          6079   314   13253     81886.0       1   \n",
       "43567       34597       18877         18047   314   17738     81859.0      13   \n",
       "\n",
       "        SectionViolations  Geo_Loc  hour  ...  State_id_1890134  \\\n",
       "42067                12.0     4242     0  ...               1.0   \n",
       "93121                32.0     9043     0  ...               1.0   \n",
       "86355                14.0    13961     0  ...               1.0   \n",
       "14478                38.0    11916     0  ...               1.0   \n",
       "112515               33.0    16551     0  ...               1.0   \n",
       "...                   ...      ...   ...  ...               ...   \n",
       "41993                32.0     9498     0  ...               1.0   \n",
       "97639                 3.0    16551     0  ...               1.0   \n",
       "95939                18.0    14718     0  ...               1.0   \n",
       "117952               11.0    12351     0  ...               1.0   \n",
       "43567                 3.0    11904     0  ...               1.0   \n",
       "\n",
       "        State_id_1890135  RiskLevel_High  RiskLevel_Low  RiskLevel_Medium  \\\n",
       "42067                0.0             0.0            0.0               1.0   \n",
       "93121                0.0             0.0            0.0               1.0   \n",
       "86355                0.0             1.0            0.0               0.0   \n",
       "14478                0.0             0.0            0.0               1.0   \n",
       "112515               0.0             0.0            0.0               1.0   \n",
       "...                  ...             ...            ...               ...   \n",
       "41993                0.0             1.0            0.0               0.0   \n",
       "97639                0.0             1.0            0.0               0.0   \n",
       "95939                0.0             1.0            0.0               0.0   \n",
       "117952               0.0             1.0            0.0               0.0   \n",
       "43567                0.0             1.0            0.0               0.0   \n",
       "\n",
       "        RiskLevel_Uncertain  State_City_id_1890134_id-11235901  \\\n",
       "42067                   0.0                                1.0   \n",
       "93121                   0.0                                1.0   \n",
       "86355                   0.0                                1.0   \n",
       "14478                   0.0                                1.0   \n",
       "112515                  0.0                                1.0   \n",
       "...                     ...                                ...   \n",
       "41993                   0.0                                1.0   \n",
       "97639                   0.0                                1.0   \n",
       "95939                   0.0                                1.0   \n",
       "117952                  0.0                                1.0   \n",
       "43567                   0.0                                1.0   \n",
       "\n",
       "        State_City_id_1890134_id-11275913  State_City_id_1890135_id-11235901  \\\n",
       "42067                                 0.0                                0.0   \n",
       "93121                                 0.0                                0.0   \n",
       "86355                                 0.0                                0.0   \n",
       "14478                                 0.0                                0.0   \n",
       "112515                                0.0                                0.0   \n",
       "...                                   ...                                ...   \n",
       "41993                                 0.0                                0.0   \n",
       "97639                                 0.0                                0.0   \n",
       "95939                                 0.0                                0.0   \n",
       "117952                                0.0                                0.0   \n",
       "43567                                 0.0                                0.0   \n",
       "\n",
       "        State_City_id_1890135_id-11275913  \n",
       "42067                                 0.0  \n",
       "93121                                 0.0  \n",
       "86355                                 0.0  \n",
       "14478                                 0.0  \n",
       "112515                                0.0  \n",
       "...                                   ...  \n",
       "41993                                 0.0  \n",
       "97639                                 0.0  \n",
       "95939                                 0.0  \n",
       "117952                                0.0  \n",
       "43567                                 0.0  \n",
       "\n",
       "[117954 rows x 37 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintrgtencohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py:633: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py:638: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.00      0.00      0.00         9\n",
      "     class 1       0.67      0.66      0.67      5747\n",
      "     class 2       0.43      0.18      0.26       258\n",
      "     class 3       0.40      0.04      0.07       909\n",
      "     class 4       0.85      0.94      0.89     15911\n",
      "     class 5       0.61      0.72      0.66      4074\n",
      "     class 6       0.68      0.35      0.46      2581\n",
      "\n",
      "    accuracy                           0.77     29489\n",
      "   macro avg       0.52      0.41      0.43     29489\n",
      "weighted avg       0.75      0.77      0.75     29489\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7675743497575367"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dataset(traintrgtencohe,testtrgtencohe , y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jaK3rthjLq22"
   },
   "outputs": [],
   "source": [
    "# X_trainSDrIMintertgenc,X_validSDrIMinter2tgenc = targetencoding(X_trainSDrIMinter2,X_validSDrIMinter2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "yWqJ47VYLq29",
    "outputId": "55b003e3-1719-4c87-9bf8-431d9b54cd12"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainSdImIn12' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-253-da7bb00a8f1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainSdImIn12lb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestSdImIn12lb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrobustlabelencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainSdImIn12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestSdImIn12\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainSdImIn12' is not defined"
     ]
    }
   ],
   "source": [
    "trainSdImIn12lb,testSdImIn12lb = robustlabelencoder(trainSdImIn12,testSdImIn12 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zqc8oJbZLq3C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-VY5Kj5Lq3G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "u3mh8M9DLq3J",
    "outputId": "7ec7345a-4dec-4561-c745-5e05383d944c"
   },
   "outputs": [],
   "source": [
    "trainSdImIn12lbohe,testSdImIn12lbohe = onhotencoder(trainSdImIn12lb,testSdImIn12lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "8SeFb6P7wSDj",
    "outputId": "5246a922-5689-41e3-f144-15112a193360"
   },
   "outputs": [],
   "source": [
    "features = trainSdImIn12lbohe.columns\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7VcTkYBfuoxw",
    "outputId": "ab52ef67-905f-4a21-a033-af890abee230"
   },
   "outputs": [],
   "source": [
    "# featres = ['LicenseNo',\n",
    "#            'FacilityID', \n",
    "#            'FacilityName', \n",
    "#            'Type', \n",
    "#            'Street',\n",
    "#            'LocationID', \n",
    "#            'Reason', \n",
    "#            'SectionViolations', \n",
    "#            'Geo_Loc',\n",
    "#            'hour', \n",
    "#            'day',\n",
    "#            'month', \n",
    "#            'year', \n",
    "            \n",
    "#            'SectionViolations_RiskLevel',\n",
    "#            'SectionViolations_Reason',\n",
    "#            'RiskLevel_Reason', \n",
    "#            'State_Street',\n",
    "#            'State_LocationID', \n",
    "#            'State_Geo_Loc',\n",
    "#            'City_Street', \n",
    "#            'City_LocationID',\n",
    "#            'City_Geo_Loc', \n",
    "#            'Street_LocationID', \n",
    "#            'Street_Geo_Loc',\n",
    "#            'LocationID_Geo_Loc', \n",
    "#            'City_id-11235901',\n",
    "#            'City_id-11275913',\n",
    "#            'State_id_1890134', \n",
    "#            'State_id_1890135', \n",
    "#            'RiskLevel_High',\n",
    "#            'RiskLevel_Low',\n",
    "#            'RiskLevel_Medium',\n",
    "#            'RiskLevel_Uncertain',\n",
    "#                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'State_City_id_1890134_id-11235901',\n",
    "#            'State_City_id_1890134_id-11275913',\n",
    "#            'State_City_id_1890135_id-11235901',\n",
    "#            'State_City_id_1890135_id-11275913'\n",
    "# drop these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropcol2(train,test):\n",
    "    cols_to_drop =['hour',\n",
    "                   'State_City_id_1890134_id-11235901',\n",
    "                   'State_City_id_1890134_id-11275913',\n",
    "                   'State_City_id_1890135_id-11235901',\n",
    "                   'State_City_id_1890135_id-11275913'\n",
    "]\n",
    "    dtrain = train.drop(cols_to_drop,axis =1)\n",
    "    dtest = test.drop(cols_to_drop,axis =1)\n",
    "    \n",
    "    print(dtrain.shape,dtest.shape)\n",
    "\n",
    "    return dtrain,dtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSdImIn12lboheD,testSdImIn12lboheD = dropcol2(trainSdImIn12lbohe,testSdImIn12lbohe )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZjbAtYuUuo_P",
    "outputId": "0dc1abab-9ba4-4962-ab73-7b874577c1a1"
   },
   "outputs": [],
   "source": [
    "#trainSdImIn12lboheLog,testSdImIn12lboheLog = createlogfestures(trainSdImIn12lbohe,testSdImIn12lbohe,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PnoVbxPJ0S0H",
    "outputId": "ed8f2533-2ddc-4587-f9b1-dd7a3864d5a4"
   },
   "outputs": [],
   "source": [
    "# trainSdImIn12lbohe,testSdImIn12lbohe = createsqrtfeatures(trainSdImIn12lbohe,testSdImIn12lbohe,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jGt_o723Lq4e"
   },
   "outputs": [],
   "source": [
    "def featureselection(train,y_train):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import ExtraTreesClassifier\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    from lightgbm import LGBMClassifier\n",
    "    from sklearn.feature_selection import chi2\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.feature_selection import RFE\n",
    "    from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "    feature_name = train.columns.tolist()\n",
    "    def cor_selector(X, y):\n",
    "        cor_list = []\n",
    "        feature_name = X.columns.tolist()\n",
    "\n",
    "        # calculate the correlation with y for each feature\n",
    "        for i in X.columns.tolist():\n",
    "            cor = np.corrcoef(X[i], y)[0, 1]\n",
    "            cor_list.append(cor)\n",
    "        # replace NaN with 0\n",
    "        cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "        # feature name\n",
    "        cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-100:]].columns.tolist()\n",
    "        # feature selection? 0 for not select, 1 for select\n",
    "        cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "        return cor_support, cor_feature\n",
    "\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=7 )\n",
    "    model_rf = SelectFromModel(rf ,threshold ='1.25*median')\n",
    "    X_new_rf = model_rf.fit(train,y_train)\n",
    "    embeded_rf_support = model_rf.get_support()\n",
    "    embeded_rf_feature = train.loc[:,embeded_rf_support].columns.tolist()\n",
    "    \n",
    "    \n",
    "    lgbc=LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\n",
    "            reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)\n",
    "    model_lgbc = SelectFromModel(lgbc,threshold = '1.25*median')\n",
    "    X_new_lgbc = model_lgbc.fit(train,y_train)\n",
    "    lgbc_rf_support = model_lgbc.get_support()\n",
    "    lgbc_rf_feature = train.loc[:,lgbc_rf_support].columns.tolist()\n",
    "    \n",
    "    \n",
    "    cor_support, cor_feature = cor_selector(train, y_train)\n",
    "    \n",
    "    \n",
    "    X_norm = MinMaxScaler().fit_transform(train)\n",
    "    \n",
    "    chi_selector = SelectKBest(chi2, k=80)\n",
    "    chi_selector.fit(X_norm, y_train)\n",
    "    chi_support = chi_selector.get_support()\n",
    "    chi_feature = train.loc[:,chi_support].columns.tolist()\n",
    "    \n",
    "    \n",
    "    rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=100, step=10, verbose=5)\n",
    "    rfe_selector.fit(X_norm, y_train)\n",
    "    rfe_support = rfe_selector.get_support()\n",
    "    rfe_feature = train.loc[:,rfe_support].columns.tolist()\n",
    "    \n",
    "    \n",
    "    embeded_lr_selector = SelectFromModel(LogisticRegression(penalty=\"l1\",solver = 'liblinear'), '1.25*median')\n",
    "    embeded_lr_selector.fit(X_norm, y_train)\n",
    "\n",
    "    embeded_lr_support = embeded_lr_selector.get_support()\n",
    "    embeded_lr_feature = train.loc[:,embeded_lr_support].columns.tolist()\n",
    "    \n",
    "    \n",
    "    pd.set_option('display.max_rows', None)\n",
    "    \n",
    "    feature_selection_df = pd.DataFrame({'Feature':feature_name, 'Pearson':cor_support, 'Chi-2':chi_support, 'RFE':rfe_support, 'Logistics':embeded_lr_support,\n",
    "                                        'Random Forest':embeded_rf_support, 'LightGBM':lgbc_rf_support})\n",
    "    \n",
    "    feature_selection_df['Total'] = np.sum(feature_selection_df, axis=1)\n",
    "    feature_selection_df = feature_selection_df.sort_values(['Total','Feature'] , ascending=False)\n",
    "    feature_selection_df.index = range(1, len(feature_selection_df)+1)\n",
    "    feature_selection_df.head(100)\n",
    "    print(feature_selection_df.columns)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featureselection(trainSdImIn12lboheLogSQ,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSdImIn12lboheD #,testSdImIn12lboheD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "clf1 = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
    "                       max_depth=None, max_features=33, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=8, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                       random_state=None, splitter='best')\n",
    "\n",
    "clf2 = BaggingClassifier(base_estimator=clf1, n_estimators=100, \n",
    "                             bootstrap=True,\n",
    "                             bootstrap_features=False, oob_score=True, warm_start=False,\n",
    "                             n_jobs=-1, random_state=786, verbose=0)\n",
    "\n",
    "# clf3=xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "#               colsample_bynode=1, colsample_bytree=0.8, gamma=0.5,\n",
    "#               learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
    "#               min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
    "#               nthread=None, objective='multi:softprob', random_state=0,\n",
    "#               reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "#               silent=None, subsample=0.6, verbosity=1)\n",
    "\n",
    "\n",
    "clf4 = LGBMClassifier(n_estimators=5000, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\n",
    "            reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf5=LGBMClassifier(n_estimators = 10000, \n",
    "    learning_rate= 0.015,\n",
    "    boosting_type = 'gbdt', \n",
    "    colsample_bytree= 0.80, \n",
    "    min_child_weight= 10.0, \n",
    "    num_leaves = 64, \n",
    "    objective='multiclass', \n",
    "    num_class= 7,\n",
    "    subsample = 0.70, \n",
    "    subsample_freq= 5,     \n",
    "    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf6=LGBMClassifier(n_estimators = 15000, \n",
    "    learning_rate= 0.01,\n",
    "    boosting_type = 'gbdt', \n",
    "    colsample_bytree= 0.80, \n",
    "    min_child_weight= 9.0, \n",
    "    num_leaves = 64, \n",
    "    objective='multiclass', \n",
    "    num_class= 7,\n",
    "    subsample = 0.85, \n",
    "    subsample_freq= 6,     \n",
    "    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4.fit(trainSdImIn12lboheD,y)\n",
    "pred4 = clf4.predict_proba(testSdImIn12lboheD)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf5.fit(trainSdImIn12lboheD,y)\n",
    "pred5 = clf5.predict_proba(testSdImIn12lboheD)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf6.fit(trainSdImIn12lboheD,y)\n",
    "pred6 = clf6.predict_proba(testSdImIn12lboheD)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub6 = pd.DataFrame(data=np.mean([pred4,pred5,pred6], axis=0)\n",
    "                         , columns=submission.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub6.to_excel(excel_writer = \"/home/ryan/stark/MachineHack/Food_QUalityA_ParticipantsData/sub6.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.fit(trainSdImIn12lboheD,y)\n",
    "\n",
    "pred1 = clf2.predict_proba(testSdImIn12lboheD)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf3.fit(trainSdImIn12lboheLogSQ,y)\n",
    "\n",
    "# pred2 = clf3.predict_proba(testSdImIn12lboheLogSQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4.fit(trainSdImIn12lboheD,y)\n",
    "\n",
    "pred3 = clf4.predict_proba(testSdImIn12lboheD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_sub1 = pd.DataFrame(data=np.mean([pred1, pred2,pred3], axis=0)\n",
    "#                          , columns=submission.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub3 = pd.DataFrame(data= pred1\n",
    "                         , columns=submission.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub4 = pd.DataFrame(data=np.mean([pred1,pred3], axis=0)\n",
    "                         , columns=submission.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub5 = pd.DataFrame(data = pred3\n",
    "                         , columns=submission.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub3.to_excel(excel_writer = \"/home/ryan/stark/MachineHack/Food_QUalityA_ParticipantsData/sub3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xt-Op3_XDPCI"
   },
   "outputs": [],
   "source": [
    "final_sub4.to_excel(excel_writer = \"/home/ryan/stark/MachineHack/Food_QUalityA_ParticipantsData/sub4.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub5.to_excel(excel_writer = \"/home/ryan/stark/MachineHack/Food_QUalityA_ParticipantsData/sub5.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "awaybasic-checkpoint.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
